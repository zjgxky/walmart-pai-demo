# dataworks/walmart_batch_prediction.py
# å¢å¼ºç‰ˆæ‰¹é‡é¢„æµ‹ - é›†æˆç‰ˆæœ¬ç®¡ç†å’Œè‡ªåŠ¨åŒ–åŠŸèƒ½

import json
import pandas as pd
import numpy as np
import time
import subprocess
from datetime import datetime

# ä½¿ç”¨DataWorkså†…ç½®çš„ODPSå¯¹è±¡ï¼Œä¸è¦è¦†ç›–å®ƒ
print("=== Walmarté”€é‡æ‰¹é‡é¢„æµ‹ - å¢å¼ºç‰ˆMLOpsæµç¨‹ ===")
print("é¡¹ç›®:", o.project)

class EnhancedMLOpsBatchPredictor:
    def __init__(self):
        # ç”Ÿæˆé¢„æµ‹ä»»åŠ¡ID
        self.prediction_id = str(int(time.time()))
        self.odps = o  # ä½¿ç”¨DataWorkså†…ç½®çš„ODPSå¯¹è±¡
        self.best_model_info = None
        self.git_info = self.get_git_version_info()
        
    def get_git_version_info(self):
        """è·å–å½“å‰ä»£ç ç‰ˆæœ¬ä¿¡æ¯"""
        try:
            # åœ¨DataWorksç¯å¢ƒä¸­ï¼Œä»£ç é€šå¸¸å·²ç»æ˜¯ä»Gitæ‹‰å–çš„
            git_info = {
                'prediction_script': 'dataworks/walmart_batch_prediction.py',
                'execution_time': datetime.now().isoformat(),
                'execution_node': 'DataWorks_PyODPS',
                'pipeline_version': 'v1.0'
            }
            
            # å°è¯•è·å–Gitä¿¡æ¯ï¼ˆå¦‚æœç¯å¢ƒæ”¯æŒï¼‰
            try:
                commit_id = subprocess.check_output(['git', 'rev-parse', 'HEAD']).decode('utf-8').strip()
                git_info['git_commit_id'] = commit_id
            except:
                git_info['git_commit_id'] = 'unknown_dataworks_env'
            
            return git_info
            
        except Exception as e:
            return {
                'prediction_script': 'dataworks/walmart_batch_prediction.py',
                'execution_time': datetime.now().isoformat(),
                'error': str(e)
            }
    
    def get_best_model_from_registry_with_versioning(self):
        """ä»PAI Model Registryè·å–æœ€ä½³æ¨¡å‹ï¼ˆå¢å¼ºç‰ˆæœ¬ç®¡ç†ï¼‰"""
        print("1. ä»PAI Model Registryè·å–æœ€ä½³æ¨¡å‹ï¼ˆç‰ˆæœ¬ç®¡ç†ï¼‰...")
        
        try:
            # é¦–å…ˆæ£€æŸ¥æ˜¯å¦å­˜åœ¨æ¨¡å‹é…ç½®è¡¨
            if self.odps.exist_table('model_config'):
                print("   ä»MaxComputeæ¨¡å‹é…ç½®è¡¨è·å–...")
                config_table = self.odps.get_table('model_config')
                config_df = config_table.to_df().to_pandas()
                
                # è·å–æœ€æ–°çš„æ´»è·ƒé…ç½®
                active_configs = config_df[config_df['status'] == 'active']
                if not active_configs.empty:
                    latest_config = active_configs.iloc[-1]
                    
                    self.best_model_info = {
                        'model_name': str(latest_config['best_model_name']),
                        'registry_name': 'walmart_sales_prediction_' + str(latest_config['best_model_name']),
                        'version': str(latest_config['model_version']),
                        'val_r2': float(latest_config['val_r2_score']),
                        'features': json.loads(latest_config['features']),
                        'config_id': str(latest_config['config_id']),
                        'source': 'maxcompute_config',
                        'training_git_commit': latest_config.get('training_git_commit', 'unknown')
                    }
                    
                    print("   âœ… ä»é…ç½®è¡¨è·å–æœ€ä½³æ¨¡å‹:", self.best_model_info['model_name'])
                    print("   âœ… æ¨¡å‹ç‰ˆæœ¬:", self.best_model_info['version'])
                    print("   âœ… è®­ç»ƒä»£ç ç‰ˆæœ¬:", self.best_model_info['training_git_commit'][:8] + "...")
                    return self.best_model_info
            
            # å›é€€æ–¹æ¡ˆ: ä»è®­ç»ƒæ€»ç»“ä¸­è·å–
            if self.odps.exist_table('training_summary'):
                print("   ä»è®­ç»ƒæ€»ç»“è¡¨è·å–...")
                summary_table = self.odps.get_table('training_summary')
                summary_df = summary_table.to_df().to_pandas()
                
                if not summary_df.empty:
                    latest_training = summary_df.iloc[-1]
                    
                    # è§£ææ¨¡å‹ä¿¡æ¯
                    models_info = json.loads(latest_training['models_info'])
                    best_model_name = latest_training['best_model_name']
                    
                    self.best_model_info = {
                        'model_name': best_model_name,
                        'registry_name': f'walmart_sales_prediction_{best_model_name}',
                        'version': models_info[best_model_name]['model_version'],
                        'val_r2': models_info[best_model_name]['metrics']['val_r2'],
                        'source': 'training_summary',
                        'training_git_commit': latest_training.get('git_commit_id', 'unknown')
                    }
                    
                    print("   âœ… ä»è®­ç»ƒæ€»ç»“è·å–æœ€ä½³æ¨¡å‹:", self.best_model_info['model_name'])
                    return self.best_model_info
            
            # æœ€ç»ˆå›é€€æ–¹æ¡ˆ
            print("   âš ï¸  ä½¿ç”¨é»˜è®¤æ¨¡å‹é…ç½®...")
            self.best_model_info = {
                'model_name': 'linear_regression',
                'registry_name': 'walmart_sales_prediction_linear_regression',
                'version': 'v_20250710_073527',
                'val_r2': 0.9431,
                'source': 'fallback',
                'training_git_commit': 'unknown'
            }
            
            print("   âœ… ä½¿ç”¨å›é€€æ¨¡å‹:", self.best_model_info['model_name'])
            return self.best_model_info
            
        except Exception as e:
            print("   âŒ è·å–æœ€ä½³æ¨¡å‹å¤±è´¥:", str(e))
            raise
    
    def load_test_data_with_validation(self):
        """åŠ è½½æµ‹è¯•æ•°æ®ï¼ˆå¢å¼ºéªŒè¯ï¼‰"""
        print("2. åŠ è½½å’ŒéªŒè¯æµ‹è¯•æ•°æ®...")
        
        try:
            # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
            if not self.odps.exist_table('walmart_test_vif'):
                raise ValueError("è¡¨ walmart_test_vif ä¸å­˜åœ¨")
            
            test_table = self.odps.get_table('walmart_test_vif')
            test_df = test_table.to_df().to_pandas()
            
            # æ•°æ®è´¨é‡æ£€æŸ¥
            print("   æ‰§è¡Œæ•°æ®è´¨é‡æ£€æŸ¥...")
            
            # æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
            missing_ratio = test_df.isnull().sum().sum() / (test_df.shape[0] * test_df.shape[1])
            print(f"   ç¼ºå¤±å€¼æ¯”ä¾‹: {missing_ratio*100:.2f}%")
            
            # æ£€æŸ¥æ•°æ®åˆ†å¸ƒ
            numeric_cols = test_df.select_dtypes(include=[np.number]).columns
            for col in numeric_cols[:5]:  # æ£€æŸ¥å‰5ä¸ªæ•°å€¼åˆ—
                mean_val = test_df[col].mean()
                std_val = test_df[col].std()
                print(f"   {col}: å‡å€¼={mean_val:.2f}, æ ‡å‡†å·®={std_val:.2f}")
            
            print("   âœ… æµ‹è¯•æ•°æ®å½¢çŠ¶:", test_df.shape)
            print("   âœ… æµ‹è¯•æ•°æ®åˆ—æ•°:", len(test_df.columns))
            print("   âœ… æ•°æ®è´¨é‡æ£€æŸ¥é€šè¿‡")
            
            return test_df
            
        except Exception as e:
            print("   âŒ åŠ è½½æµ‹è¯•æ•°æ®å¤±è´¥:", str(e))
            raise
    
    def predict_with_versioned_model(self, test_df):
        """ä½¿ç”¨ç‰ˆæœ¬åŒ–æ¨¡å‹è¿›è¡Œé¢„æµ‹"""
        print("3. ä½¿ç”¨ç‰ˆæœ¬åŒ–æ¨¡å‹è¿›è¡Œé¢„æµ‹...")
        
        try:
            # è®°å½•é¢„æµ‹ç¯å¢ƒä¿¡æ¯
            prediction_env = {
                'execution_time': datetime.now().isoformat(),
                'execution_node': 'DataWorks_PyODPS',
                'model_source': self.best_model_info['source'],
                'training_code_version': self.best_model_info.get('training_git_commit', 'unknown'),
                'prediction_code_version': self.git_info.get('git_commit_id', 'unknown'),
                'data_version': test_df.shape
            }
            
            print("   âœ… é¢„æµ‹ç¯å¢ƒä¿¡æ¯:")
            print(f"      æ¨¡å‹æ¥æº: {prediction_env['model_source']}")
            print(f"      è®­ç»ƒä»£ç ç‰ˆæœ¬: {prediction_env['training_code_version'][:8]}...")
            print(f"      é¢„æµ‹ä»£ç ç‰ˆæœ¬: {prediction_env['prediction_code_version'][:8]}...")
            
            # ä½¿ç”¨æ¨¡æ‹Ÿé¢„æµ‹ï¼ˆåœ¨å®é™…ç¯å¢ƒä¸­è¿™é‡Œä¼šåŠ è½½çœŸå®æ¨¡å‹ï¼‰
            predictions = self._simulate_versioned_prediction(test_df)
            
            # ç¡®ä¿é¢„æµ‹å€¼åˆç†
            predictions = np.maximum(predictions, 0)  # é”€å”®é¢ä¸èƒ½ä¸ºè´Ÿ
            
            # è®¡ç®—é¢„æµ‹ç»Ÿè®¡
            pred_stats = {
                "count": len(predictions),
                "mean": float(np.mean(predictions)),
                "std": float(np.std(predictions)),
                "min": float(np.min(predictions)),
                "max": float(np.max(predictions)),
                "median": float(np.median(predictions))
            }
            
            print("   âœ… é¢„æµ‹å®Œæˆ:", pred_stats['count'], "ä¸ªæ ·æœ¬")
            print("   âœ… é¢„æµ‹ç»Ÿè®¡: å‡å€¼=", round(pred_stats['mean'], 2))
            print("   âœ… é¢„æµ‹èŒƒå›´: [", round(pred_stats['min'], 2), ",", round(pred_stats['max'], 2), "]")
            
            return predictions, pred_stats, prediction_env
            
        except Exception as e:
            print("   âŒ æ¨¡å‹é¢„æµ‹å¤±è´¥:", str(e))
            raise
    
    def _simulate_versioned_prediction(self, test_df):
        """ç‰ˆæœ¬åŒ–æ¨¡æ‹Ÿé¢„æµ‹"""
        print("   ä½¿ç”¨ç‰ˆæœ¬åŒ–æ¨¡æ‹Ÿé¢„æµ‹...")
        
        features = self._get_model_features(test_df)
        print("   ç‰¹å¾æ•°é‡:", len(features))
        
        # å¡«å……ç¼ºå¤±å€¼
        X = test_df[features].fillna(0)
        
        # åŸºäºæ¨¡å‹ç±»å‹å’Œç‰ˆæœ¬ä½¿ç”¨ä¸åŒçš„é¢„æµ‹ç­–ç•¥
        model_name = self.best_model_info['model_name']
        model_version = self.best_model_info.get('version', 'v1.0')
        
        # è®¾ç½®éšæœºç§å­ç¡®ä¿å¯é‡ç°æ€§
        np.random.seed(hash(model_version) % 2**32)
        
        if model_name == 'linear_regression':
            # çº¿æ€§å›å½’æ¨¡æ‹Ÿ
            coefficients = np.random.normal(0, 1000, len(features))
            
            # è°ƒæ•´å…³é”®ç‰¹å¾æƒé‡
            for i, feature in enumerate(features):
                feature_lower = feature.lower()
                if any(keyword in feature_lower for keyword in ['holiday', 'temperature', 'fuel']):
                    coefficients[i] = abs(coefficients[i]) * 2
                elif 'unemployment' in feature_lower:
                    coefficients[i] = -abs(coefficients[i])
            
            predictions = np.dot(X.values, coefficients) + 50000
            
        elif model_name == 'elastic_net':
            # å¼¹æ€§ç½‘ç»œæ¨¡æ‹Ÿï¼ˆç¨€ç–ï¼‰
            coefficients = np.random.normal(0, 800, len(features))
            zero_mask = np.random.random(len(features)) < 0.3
            coefficients[zero_mask] = 0
            
            predictions = np.dot(X.values, coefficients) + 48000
            
        else:  # random_forest
            # éšæœºæ£®æ—æ¨¡æ‹Ÿï¼ˆéçº¿æ€§ï¼‰
            base_pred = np.random.normal(52000, 5000, len(X))
            feature_effects = np.sum(X.values * np.random.normal(0, 100, X.shape[1]), axis=1)
            predictions = base_pred + feature_effects
        
        print(f"   ä½¿ç”¨æ¨¡å‹: {model_name} (ç‰ˆæœ¬: {model_version})")
        return predictions
    
    def _get_model_features(self, test_df):
        """è·å–æ¨¡å‹ç‰¹å¾åˆ—è¡¨"""
        if 'features' in self.best_model_info:
            return self.best_model_info['features']
        else:
            # åŸºäºè®­ç»ƒæ—¶çš„ç‰¹å¾å·¥ç¨‹ï¼Œæ’é™¤ç›®æ ‡å˜é‡
            features = [col for col in test_df.columns if col.lower() != 'weekly_sales']
            return features
    
    def save_predictions_with_lineage(self, test_df, predictions, pred_stats, prediction_env):
        """ä¿å­˜é¢„æµ‹ç»“æœï¼ˆåŒ…å«æ•°æ®è¡€ç¼˜ï¼‰"""
        print("4. ä¿å­˜é¢„æµ‹ç»“æœï¼ˆåŒ…å«æ•°æ®è¡€ç¼˜ï¼‰...")
        
        try:
            # åˆ›å»ºé¢„æµ‹ç»“æœè¡¨
            output_table = "walmart_sales_predictions_v2"
            
            # å‡†å¤‡ç»“æœæ•°æ®
            result_df = test_df.copy()
            result_df['predicted_weekly_sales'] = predictions
            result_df['prediction_id'] = self.prediction_id
            result_df['model_name'] = self.best_model_info['model_name']
            result_df['model_version'] = self.best_model_info['version']
            result_df['model_val_r2'] = self.best_model_info['val_r2']
            
            # æ·»åŠ ç‰ˆæœ¬è¿½è¸ªä¿¡æ¯
            result_df['training_git_commit'] = self.best_model_info.get('training_git_commit', 'unknown')
            result_df['prediction_git_commit'] = self.git_info.get('git_commit_id', 'unknown')
            result_df['prediction_time'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            result_df['execution_node'] = 'DataWorks_PyODPS'
            
            print("   å‡†å¤‡å†™å…¥æ•°æ®ï¼Œè¡Œæ•°:", len(result_df))
            
            # åˆ é™¤æ—§è¡¨å¹¶åˆ›å»ºæ–°è¡¨
            if self.odps.exist_table(output_table):
                self.odps.delete_table(output_table)
                print("   åˆ é™¤æ—§è¡¨:", output_table)
            
            # åˆ›å»ºè¡¨ç»“æ„
            from odps.models import Schema, Column
            
            columns = []
            for col in test_df.columns:
                col_type = str(test_df[col].dtype)
                if col_type == 'object':
                    columns.append(Column(name=col, type='string'))
                elif 'int' in col_type:
                    columns.append(Column(name=col, type='bigint'))
                else:
                    columns.append(Column(name=col, type='double'))
            
            # æ·»åŠ é¢„æµ‹ç»“æœå’Œç‰ˆæœ¬è¿½è¸ªåˆ—
            columns.extend([
                Column(name='predicted_weekly_sales', type='double'),
                Column(name='prediction_id', type='string'),
                Column(name='model_name', type='string'),
                Column(name='model_version', type='string'),
                Column(name='model_val_r2', type='double'),
                Column(name='training_git_commit', type='string'),
                Column(name='prediction_git_commit', type='string'),
                Column(name='prediction_time', type='string'),
                Column(name='execution_node', type='string')
            ])
            
            # åˆ›å»ºSchemaå¯¹è±¡
            schema = Schema(columns=columns)
            
            # åˆ›å»ºè¡¨
            self.odps.create_table(output_table, schema)
            print("   åˆ›å»ºæ–°è¡¨:", output_table)
            
            # æ‰¹é‡å†™å…¥æ•°æ®
            table = self.odps.get_table(output_table)
            with table.open_writer() as writer:
                batch_size = 1000
                total_written = 0
                
                for i in range(0, len(result_df), batch_size):
                    batch = result_df.iloc[i:i+batch_size]
                    records = []
                    
                    for _, row in batch.iterrows():
                        record = []
                        # æŒ‰ç…§Schemaä¸­å®šä¹‰çš„åˆ—é¡ºåºå†™å…¥æ•°æ®
                        for col in columns:
                            col_name = col.name
                            value = row[col_name]
                            if pd.isna(value):
                                record.append(None)
                            else:
                                record.append(value)
                        records.append(record)
                    
                    writer.write(records)
                    total_written += len(records)
                    
                    if total_written % 5000 == 0:
                        print("   å·²å†™å…¥:", total_written, "è¡Œ")
                
                print("   âœ… æ•°æ®å†™å…¥å®Œæˆï¼Œæ€»è¡Œæ•°:", total_written)
            
            # ä¿å­˜æ•°æ®è¡€ç¼˜ä¿¡æ¯
            self._save_data_lineage(output_table, prediction_env)
                    
            print("   âœ… é¢„æµ‹ç»“æœå·²ä¿å­˜åˆ°:", output_table)
            
            return output_table
            
        except Exception as e:
            print("   âŒ ä¿å­˜é¢„æµ‹ç»“æœå¤±è´¥:", str(e))
            raise
    
    def _save_data_lineage(self, output_table, prediction_env):
        """ä¿å­˜æ•°æ®è¡€ç¼˜ä¿¡æ¯"""
        try:
            lineage_table = "prediction_data_lineage"
            
            lineage_info = {
                'prediction_id': self.prediction_id,
                'output_table': output_table,
                'input_tables': ['walmart_test_vif'],
                'model_registry_name': self.best_model_info['registry_name'],
                'training_git_commit': self.best_model_info.get('training_git_commit', 'unknown'),
                'prediction_git_commit': self.git_info.get('git_commit_id', 'unknown'),
                'execution_time': prediction_env['execution_time'],
                'execution_node': prediction_env['execution_node'],
                'data_version': str(prediction_env['data_version']),
                'lineage_type': 'batch_prediction'
            }
            
            # åˆ›å»ºè¡€ç¼˜è¡¨ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
            from odps.models import Schema, Column
            
            if not self.odps.exist_table(lineage_table):
                lineage_columns = [
                    Column(name='prediction_id', type='string'),
                    Column(name='output_table', type='string'),
                    Column(name='input_tables', type='string'),
                    Column(name='model_registry_name', type='string'),
                    Column(name='training_git_commit', type='string'),
                    Column(name='prediction_git_commit', type='string'),
                    Column(name='execution_time', type='string'),
                    Column(name='execution_node', type='string'),
                    Column(name='data_version', type='string'),
                    Column(name='lineage_type', type='string')
                ]
                
                lineage_schema = Schema(columns=lineage_columns)
                self.odps.create_table(lineage_table, lineage_schema)
            
            # å†™å…¥è¡€ç¼˜ä¿¡æ¯
            table = self.odps.get_table(lineage_table)
            with table.open_writer() as writer:
                record = [
                    lineage_info['prediction_id'],
                    lineage_info['output_table'],
                    json.dumps(lineage_info['input_tables']),
                    lineage_info['model_registry_name'],
                    lineage_info['training_git_commit'],
                    lineage_info['prediction_git_commit'],
                    lineage_info['execution_time'],
                    lineage_info['execution_node'],
                    lineage_info['data_version'],
                    lineage_info['lineage_type']
                ]
                writer.write([record])
            
            print("   âœ… æ•°æ®è¡€ç¼˜ä¿¡æ¯å·²ä¿å­˜")
            
        except Exception as e:
            print("   âš ï¸ ä¿å­˜æ•°æ®è¡€ç¼˜å¤±è´¥:", str(e))
    
    def update_model_deployment_status_v2(self, output_table, pred_stats, prediction_env):
        """æ›´æ–°æ¨¡å‹éƒ¨ç½²çŠ¶æ€ï¼ˆå¢å¼ºç‰ˆæœ¬ç®¡ç†ï¼‰"""
        print("5. æ›´æ–°æ¨¡å‹éƒ¨ç½²çŠ¶æ€ï¼ˆç‰ˆæœ¬ç®¡ç†ï¼‰...")
        
        try:
            # åˆ›å»ºå¢å¼ºç‰ˆéƒ¨ç½²çŠ¶æ€è¡¨
            deploy_table = "model_deployment_status_v2"
            
            deploy_info = {
                'prediction_id': self.prediction_id,
                'model_name': self.best_model_info['model_name'],
                'registry_name': self.best_model_info['registry_name'],
                'model_version': self.best_model_info['version'],
                'val_r2_score': self.best_model_info['val_r2'],
                'prediction_count': pred_stats['count'],
                'prediction_mean': pred_stats['mean'],
                'prediction_table': output_table,
                'deployment_status': 'approved',
                'next_action': 'deploy_to_eas',
                
                # ç‰ˆæœ¬è¿½è¸ªä¿¡æ¯
                'training_git_commit': self.best_model_info.get('training_git_commit', 'unknown'),
                'prediction_git_commit': self.git_info.get('git_commit_id', 'unknown'),
                'execution_node': prediction_env['execution_node'],
                'code_lineage': json.dumps({
                    'training_repo': 'https://github.com/your-username/walmart-pai-demo',
                    'training_script': 'notebooks/Walmart_Training.ipynb',
                    'prediction_script': 'dataworks/walmart_batch_prediction.py',
                    'training_commit': self.best_model_info.get('training_git_commit', 'unknown'),
                    'prediction_commit': self.git_info.get('git_commit_id', 'unknown')
                }),
                'created_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            }
            
            # åˆ›å»ºå¢å¼ºç‰ˆéƒ¨ç½²çŠ¶æ€è¡¨
            from odps.models import Schema, Column
            
            deploy_columns = [
                Column(name='prediction_id', type='string'),
                Column(name='model_name', type='string'),
                Column(name='registry_name', type='string'),
                Column(name='model_version', type='string'),
                Column(name='val_r2_score', type='double'),
                Column(name='prediction_count', type='bigint'),
                Column(name='prediction_mean', type='double'),
                Column(name='prediction_table', type='string'),
                Column(name='deployment_status', type='string'),
                Column(name='next_action', type='string'),
                Column(name='training_git_commit', type='string'),
                Column(name='prediction_git_commit', type='string'),
                Column(name='execution_node', type='string'),
                Column(name='code_lineage', type='string'),
                Column(name='created_time', type='string')
            ]
            
            deploy_schema = Schema(columns=deploy_columns)
            
            if self.odps.exist_table(deploy_table):
                self.odps.delete_table(deploy_table)
            
            self.odps.create_table(deploy_table, deploy_schema)
            
            # å†™å…¥éƒ¨ç½²ä¿¡æ¯
            table = self.odps.get_table(deploy_table)
            with table.open_writer() as writer:
                record = [
                    deploy_info['prediction_id'],
                    deploy_info['model_name'],
                    deploy_info['registry_name'],
                    deploy_info['model_version'],
                    deploy_info['val_r2_score'],
                    deploy_info['prediction_count'],
                    deploy_info['prediction_mean'],
                    deploy_info['prediction_table'],
                    deploy_info['deployment_status'],
                    deploy_info['next_action'],
                    deploy_info['training_git_commit'],
                    deploy_info['prediction_git_commit'],
                    deploy_info['execution_node'],
                    deploy_info['code_lineage'],
                    deploy_info['created_time']
                ]
                writer.write([record])
            
            print("   âœ… å¢å¼ºç‰ˆéƒ¨ç½²çŠ¶æ€å·²æ›´æ–°:", deploy_table)
            print("   âœ… æ¨¡å‹å·²æ‰¹å‡†éƒ¨ç½²åˆ°EAS")
            print("   âœ… ä»£ç ç‰ˆæœ¬è¿½è¸ªå·²è®°å½•")
            
            return deploy_info
            
        except Exception as e:
            print("   âŒ æ›´æ–°éƒ¨ç½²çŠ¶æ€å¤±è´¥:", str(e))
            raise

def main():
    """ä¸»æ‰¹é‡é¢„æµ‹å‡½æ•°ï¼ˆå¢å¼ºç‰ˆï¼‰"""
    predictor = EnhancedMLOpsBatchPredictor()
    
    try:
        # 1. è·å–ç‰ˆæœ¬åŒ–çš„æœ€ä½³æ¨¡å‹
        best_model_info = predictor.get_best_model_from_registry_with_versioning()
        
        # 2. åŠ è½½å’ŒéªŒè¯æµ‹è¯•æ•°æ®
        test_df = predictor.load_test_data_with_validation()
        
        # 3. æ‰§è¡Œç‰ˆæœ¬åŒ–é¢„æµ‹
        predictions, pred_stats, prediction_env = predictor.predict_with_versioned_model(test_df)
        
        # 4. ä¿å­˜é¢„æµ‹ç»“æœï¼ˆåŒ…å«æ•°æ®è¡€ç¼˜ï¼‰
        output_table = predictor.save_predictions_with_lineage(test_df, predictions, pred_stats, prediction_env)
        
        # 5. æ›´æ–°å¢å¼ºç‰ˆéƒ¨ç½²çŠ¶æ€
        deploy_info = predictor.update_model_deployment_status_v2(output_table, pred_stats, prediction_env)
        
        # 6. è¾“å‡ºå¢å¼ºç‰ˆæ€»ç»“
        print("\n=== å¢å¼ºç‰ˆæ‰¹é‡é¢„æµ‹å®Œæˆæ€»ç»“ ===")
        print("é¢„æµ‹ä»»åŠ¡ID:", predictor.prediction_id)
        print("ä½¿ç”¨æ¨¡å‹:", best_model_info['model_name'])
        print("æ¨¡å‹ç‰ˆæœ¬:", best_model_info['version'])
        print("æ¨¡å‹éªŒè¯é›†RÂ²:", round(best_model_info['val_r2'], 4))
        print("é¢„æµ‹æ ·æœ¬æ•°:", pred_stats['count'])
        print("é¢„æµ‹ç»“æœè¡¨:", output_table)
        print("é¢„æµ‹å‡å€¼:", round(pred_stats['mean'], 2))
        
        print("\n=== ç‰ˆæœ¬è¿½è¸ªä¿¡æ¯ ===")
        print("è®­ç»ƒä»£ç ç‰ˆæœ¬:", best_model_info.get('training_git_commit', 'unknown')[:8] + "...")
        print("é¢„æµ‹ä»£ç ç‰ˆæœ¬:", predictor.git_info.get('git_commit_id', 'unknown')[:8] + "...")
        print("æ‰§è¡ŒèŠ‚ç‚¹:", prediction_env['execution_node'])
        print("æ•°æ®è¡€ç¼˜:", "å·²è®°å½•åˆ° prediction_data_lineage è¡¨")
        
        print("\n=== éƒ¨ç½²çŠ¶æ€ ===")
        print("éƒ¨ç½²çŠ¶æ€:", deploy_info['deployment_status'])
        print("ä¸‹ä¸€æ­¥æ“ä½œ:", deploy_info['next_action'])
        
        # ä¸ºä¸‹ä¸€æ­¥EASéƒ¨ç½²å‡†å¤‡ä¿¡æ¯
        eas_deploy_info = {
            'model_registry_name': best_model_info['registry_name'],
            'model_version': best_model_info['version'],
            'deployment_status': deploy_info['deployment_status'],
            'prediction_performance': pred_stats,
            'code_lineage': json.loads(deploy_info['code_lineage'])
        }
        
        print("\n=== EASéƒ¨ç½²å‡†å¤‡ä¿¡æ¯ ===")
        print("Registryæ¨¡å‹å:", eas_deploy_info['model_registry_name'])
        print("æ¨¡å‹ç‰ˆæœ¬:", eas_deploy_info['model_version'])
        print("éƒ¨ç½²çŠ¶æ€:", eas_deploy_info['deployment_status'])
        print("ä»£ç å¯è¿½æº¯æ€§:", "å®Œæ•´")
        
        return predictor.prediction_id, output_table, eas_deploy_info
        
    except Exception as e:
        print("âŒ å¢å¼ºç‰ˆæ‰¹é‡é¢„æµ‹å¤±è´¥:", str(e))
        raise

# æ‰§è¡Œå¢å¼ºç‰ˆæ‰¹é‡é¢„æµ‹
prediction_id, output_table, eas_info = main()
print(f"\nâœ… å¢å¼ºç‰ˆæ‰¹é‡é¢„æµ‹ä»»åŠ¡å®Œæˆ - ID: {prediction_id}")
print("ğŸ”„ ç‰ˆæœ¬ç®¡ç†å’Œä»£ç è¿½è¸ªåŠŸèƒ½å·²é›†æˆï¼")