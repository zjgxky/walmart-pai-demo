{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f3b7057-6af3-4f6a-bd9b-0a708cbe7a16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-09T06:44:12.974563Z",
     "iopub.status.busy": "2025-07-09T06:44:12.974226Z",
     "iopub.status.idle": "2025-07-09T06:44:12.982059Z",
     "shell.execute_reply": "2025-07-09T06:44:12.981331Z",
     "shell.execute_reply.started": "2025-07-09T06:44:12.974539Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前目录文件:\n",
      "['Walmart.csv', '.ipynb_checkpoints', 'Untitled.ipynb', '.virtual_documents']\n",
      "✅ Walmart.csv 上传成功!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"当前目录文件:\")\n",
    "print(os.listdir('.'))\n",
    "\n",
    "# 检查CSV文件是否存在\n",
    "if 'Walmart.csv' in os.listdir('.'):\n",
    "    print(\"✅ Walmart.csv 上传成功!\")\n",
    "else:\n",
    "    print(\"❌ 未找到Walmart.csv文件\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bd482ec-eeaa-4159-84f8-617fb5c80afa",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-07-09T07:01:26.009585Z",
     "iopub.status.busy": "2025-07-09T07:01:26.009257Z",
     "iopub.status.idle": "2025-07-09T07:01:26.015329Z",
     "shell.execute_reply": "2025-07-09T07:01:26.014565Z",
     "shell.execute_reply.started": "2025-07-09T07:01:26.009563Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ 连接失败\n",
      "检查表时出错: 'NoneType' object has no attribute 'get_table'\n"
     ]
    }
   ],
   "source": [
    "# 在DSW中运行这个检查\n",
    "from odps import ODPS\n",
    "import pandas as pd\n",
    "\n",
    "# 连接MaxCompute\n",
    "try:\n",
    "    odps = ODPS.from_environments()\n",
    "    print(f\"✅ 连接成功，项目: {odps.project}\")\n",
    "except:\n",
    "    print(\"❌ 连接失败\")\n",
    "\n",
    "# 检查表是否存在和数据\n",
    "try:\n",
    "    # 检查表\n",
    "    table = odps.get_table('walmart_sales_raw')\n",
    "    print(f\"表 walmart_sales_raw 存在\")\n",
    "    print(f\"表结构: {[col.name for col in table.schema.columns]}\")\n",
    "    \n",
    "    # 检查数据量\n",
    "    count_sql = \"SELECT COUNT(*) as cnt FROM walmart_sales_raw\"\n",
    "    result = odps.execute_sql(count_sql)\n",
    "    record_count = list(result)[0].cnt\n",
    "    print(f\"表中记录数: {record_count}\")\n",
    "    \n",
    "    if record_count == 0:\n",
    "        print(\"❌ 表中没有数据\")\n",
    "    else:\n",
    "        print(\"✅ 表中有数据\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"检查表时出错: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c6834fe-bf20-4f83-925c-77fb705c1e77",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-07-09T07:18:07.318013Z",
     "iopub.status.busy": "2025-07-09T07:18:07.317472Z",
     "iopub.status.idle": "2025-07-09T07:18:21.275933Z",
     "shell.execute_reply": "2025-07-09T07:18:21.274525Z",
     "shell.execute_reply.started": "2025-07-09T07:18:07.317978Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 修复数据格式并重新上传...\n",
      "使用现有连接: ds_case_demo\n",
      "\n",
      "📁 重新读取和处理CSV数据...\n",
      "原始数据形状: (6435, 8)\n",
      "原始列名: ['Store', 'Date', 'Weekly_Sales', 'Holiday_Flag', 'Temperature', 'Fuel_Price', 'CPI', 'Unemployment']\n",
      "前3行数据:\n",
      "   Store        Date  Weekly_Sales  Holiday_Flag  Temperature  Fuel_Price  \\\n",
      "0      1  05-02-2010    1643690.90             0        42.31       2.572   \n",
      "1      1  12-02-2010    1641957.44             1        38.51       2.548   \n",
      "2      1  19-02-2010    1611968.17             0        39.93       2.514   \n",
      "\n",
      "          CPI  Unemployment  \n",
      "0  211.096358         8.106  \n",
      "1  211.242170         8.106  \n",
      "2  211.289143         8.106  \n",
      "\n",
      "🧹 详细数据清洗...\n",
      "重命名后的列: ['store', 'date_str', 'weekly_sales', 'holiday_flag', 'temperature', 'fuel_price', 'cpi', 'unemployment']\n",
      "\n",
      "📊 数据类型处理...\n",
      "处理前的数据类型:\n",
      "store             int64\n",
      "date_str         object\n",
      "weekly_sales    float64\n",
      "holiday_flag      int64\n",
      "temperature     float64\n",
      "fuel_price      float64\n",
      "cpi             float64\n",
      "unemployment    float64\n",
      "dtype: object\n",
      "✅ store列处理完成\n",
      "✅ date_str列处理完成\n",
      "✅ weekly_sales列处理完成\n",
      "✅ holiday_flag列处理完成\n",
      "✅ temperature列处理完成\n",
      "✅ fuel_price列处理完成\n",
      "✅ cpi列处理完成\n",
      "✅ unemployment列处理完成\n",
      "\n",
      "处理后的数据类型:\n",
      "store             int64\n",
      "date_str         object\n",
      "weekly_sales    float64\n",
      "holiday_flag      int64\n",
      "temperature     float64\n",
      "fuel_price      float64\n",
      "cpi             float64\n",
      "unemployment    float64\n",
      "dtype: object\n",
      "\n",
      "🔍 检查缺失值...\n",
      "缺失值统计:\n",
      "store           0\n",
      "date_str        0\n",
      "weekly_sales    0\n",
      "holiday_flag    0\n",
      "temperature     0\n",
      "fuel_price      0\n",
      "cpi             0\n",
      "unemployment    0\n",
      "dtype: int64\n",
      "\n",
      "清洗后数据: 6435 → 6435 行\n",
      "\n",
      "清洗后的样本数据:\n",
      "   store    date_str  weekly_sales  holiday_flag  temperature  fuel_price  \\\n",
      "0      1  05-02-2010    1643690.90             0        42.31       2.572   \n",
      "1      1  12-02-2010    1641957.44             1        38.51       2.548   \n",
      "2      1  19-02-2010    1611968.17             0        39.93       2.514   \n",
      "\n",
      "          cpi  unemployment  \n",
      "0  211.096358         8.106  \n",
      "1  211.242170         8.106  \n",
      "2  211.289143         8.106  \n",
      "\n",
      "📋 检查MaxCompute表结构...\n",
      "表结构信息:\n",
      "  store: BIGINT\n",
      "  date_str: STRING\n",
      "  weekly_sales: DOUBLE\n",
      "  holiday_flag: BIGINT\n",
      "  temperature: DOUBLE\n",
      "  fuel_price: DOUBLE\n",
      "  cpi: DOUBLE\n",
      "  unemployment: DOUBLE\n",
      "\n",
      "🔄 准备上传格式...\n",
      "开始准备数据...\n",
      "准备进度: 1000/6435\n",
      "准备进度: 2000/6435\n",
      "准备进度: 3000/6435\n",
      "准备进度: 4000/6435\n",
      "准备进度: 5000/6435\n",
      "准备进度: 6000/6435\n",
      "✅ 准备完成，共 6435 条记录\n",
      "前3条准备好的记录:\n",
      "  记录 1: (1, '05-02-2010', 1643690.9, 0, 42.31, 2.572, 211.0963582, 8.106)\n",
      "  记录 2: (1, '12-02-2010', 1641957.44, 1, 38.51, 2.548, 211.2421698, 8.106)\n",
      "  记录 3: (1, '19-02-2010', 1611968.17, 0, 39.93, 2.514, 211.2891429, 8.106)\n",
      "\n",
      "⬆️ 开始上传准备好的数据...\n",
      "清空现有数据...\n",
      "✅ 表已清空\n",
      "开始批量上传，总计 6435 条记录\n",
      "批次 1: 1000 条记录 | 进度: 15.5%\n",
      "批次 2: 1000 条记录 | 进度: 31.1%\n",
      "批次 3: 1000 条记录 | 进度: 46.6%\n",
      "批次 4: 1000 条记录 | 进度: 62.2%\n",
      "批次 5: 1000 条记录 | 进度: 77.7%\n",
      "批次 6: 1000 条记录 | 进度: 93.2%\n",
      "批次 7: 435 条记录 | 进度: 100.0%\n",
      "✅ 数据写入完成!\n",
      "\n",
      "🔍 验证上传结果...\n",
      "✅ 最终记录数: 6435\n",
      "\n",
      "📋 MaxCompute中的样本数据:\n",
      "  行 1: 门店=1, 日期=05-02-2010, 销量=1643690.9\n",
      "  行 2: 门店=1, 日期=12-02-2010, 销量=1641957.44\n",
      "  行 3: 门店=1, 日期=19-02-2010, 销量=1611968.17\n",
      "  行 4: 门店=1, 日期=26-02-2010, 销量=1409727.59\n",
      "  行 5: 门店=1, 日期=05-03-2010, 销量=1554806.68\n",
      "\n",
      "🎉 数据上传完全成功!\n",
      "现在可以在DataWorks中查询数据了!\n"
     ]
    }
   ],
   "source": [
    "# 修复数据格式问题的上传代码\n",
    "\n",
    "import pandas as pd\n",
    "from odps import ODPS\n",
    "import numpy as np\n",
    "\n",
    "print(\"🔧 修复数据格式并重新上传...\")\n",
    "\n",
    "# 使用已建立的连接\n",
    "print(\"使用现有连接:\", odps.project)\n",
    "\n",
    "# 读取CSV数据\n",
    "print(\"\\n📁 重新读取和处理CSV数据...\")\n",
    "try:\n",
    "    df = pd.read_csv('Walmart.csv')\n",
    "    print(f\"原始数据形状: {df.shape}\")\n",
    "    print(f\"原始列名: {list(df.columns)}\")\n",
    "    print(\"前3行数据:\")\n",
    "    print(df.head(3))\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ 读取CSV失败: {e}\")\n",
    "    raise\n",
    "\n",
    "# 数据清洗和格式转换\n",
    "print(\"\\n🧹 详细数据清洗...\")\n",
    "\n",
    "# 重命名列\n",
    "df.columns = ['store', 'date_str', 'weekly_sales', 'holiday_flag', \n",
    "              'temperature', 'fuel_price', 'cpi', 'unemployment']\n",
    "\n",
    "print(\"重命名后的列:\", list(df.columns))\n",
    "\n",
    "# 数据类型检查和转换\n",
    "print(\"\\n📊 数据类型处理...\")\n",
    "print(\"处理前的数据类型:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# 逐列处理数据类型\n",
    "df_processed = pd.DataFrame()\n",
    "\n",
    "# 处理store列 - 转换为整数\n",
    "try:\n",
    "    df_processed['store'] = pd.to_numeric(df['store'], errors='coerce').astype('int64')\n",
    "    print(\"✅ store列处理完成\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ store列处理失败: {e}\")\n",
    "\n",
    "# 处理date_str列 - 确保为字符串\n",
    "try:\n",
    "    df_processed['date_str'] = df['date_str'].astype(str)\n",
    "    print(\"✅ date_str列处理完成\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ date_str列处理失败: {e}\")\n",
    "\n",
    "# 处理weekly_sales列 - 转换为浮点数\n",
    "try:\n",
    "    df_processed['weekly_sales'] = pd.to_numeric(df['weekly_sales'], errors='coerce').astype('float64')\n",
    "    print(\"✅ weekly_sales列处理完成\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ weekly_sales列处理失败: {e}\")\n",
    "\n",
    "# 处理holiday_flag列 - 转换为整数\n",
    "try:\n",
    "    df_processed['holiday_flag'] = pd.to_numeric(df['holiday_flag'], errors='coerce').astype('int64')\n",
    "    print(\"✅ holiday_flag列处理完成\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ holiday_flag列处理失败: {e}\")\n",
    "\n",
    "# 处理temperature列 - 转换为浮点数\n",
    "try:\n",
    "    df_processed['temperature'] = pd.to_numeric(df['temperature'], errors='coerce').astype('float64')\n",
    "    print(\"✅ temperature列处理完成\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ temperature列处理失败: {e}\")\n",
    "\n",
    "# 处理fuel_price列 - 转换为浮点数\n",
    "try:\n",
    "    df_processed['fuel_price'] = pd.to_numeric(df['fuel_price'], errors='coerce').astype('float64')\n",
    "    print(\"✅ fuel_price列处理完成\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ fuel_price列处理失败: {e}\")\n",
    "\n",
    "# 处理cpi列 - 转换为浮点数\n",
    "try:\n",
    "    df_processed['cpi'] = pd.to_numeric(df['cpi'], errors='coerce').astype('float64')\n",
    "    print(\"✅ cpi列处理完成\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ cpi列处理失败: {e}\")\n",
    "\n",
    "# 处理unemployment列 - 转换为浮点数\n",
    "try:\n",
    "    df_processed['unemployment'] = pd.to_numeric(df['unemployment'], errors='coerce').astype('float64')\n",
    "    print(\"✅ unemployment列处理完成\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ unemployment列处理失败: {e}\")\n",
    "\n",
    "print(\"\\n处理后的数据类型:\")\n",
    "print(df_processed.dtypes)\n",
    "\n",
    "# 检查和处理缺失值\n",
    "print(\"\\n🔍 检查缺失值...\")\n",
    "missing_counts = df_processed.isnull().sum()\n",
    "print(\"缺失值统计:\")\n",
    "print(missing_counts)\n",
    "\n",
    "# 删除有缺失值的行\n",
    "df_clean = df_processed.dropna()\n",
    "print(f\"\\n清洗后数据: {len(df_processed)} → {len(df_clean)} 行\")\n",
    "\n",
    "print(\"\\n清洗后的样本数据:\")\n",
    "print(df_clean.head(3))\n",
    "\n",
    "# 检查MaxCompute表结构\n",
    "print(\"\\n📋 检查MaxCompute表结构...\")\n",
    "try:\n",
    "    table = odps.get_table('walmart_sales_raw')\n",
    "    print(\"表结构信息:\")\n",
    "    for col in table.table_schema.columns:\n",
    "        print(f\"  {col.name}: {col.type}\")\n",
    "except Exception as e:\n",
    "    print(f\"获取表结构失败: {e}\")\n",
    "\n",
    "# 准备上传数据 - 转换为适合MaxCompute的格式\n",
    "print(\"\\n🔄 准备上传格式...\")\n",
    "\n",
    "def prepare_data_for_maxcompute(df):\n",
    "    \"\"\"准备适合MaxCompute的数据格式\"\"\"\n",
    "    prepared_data = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        # 将每行转换为tuple格式，这是MaxCompute writer期望的格式\n",
    "        record = (\n",
    "            int(row['store']),                    # BIGINT\n",
    "            str(row['date_str']),                 # STRING\n",
    "            float(row['weekly_sales']),           # DOUBLE\n",
    "            int(row['holiday_flag']),             # BIGINT\n",
    "            float(row['temperature']),            # DOUBLE\n",
    "            float(row['fuel_price']),             # DOUBLE\n",
    "            float(row['cpi']),                    # DOUBLE\n",
    "            float(row['unemployment'])            # DOUBLE\n",
    "        )\n",
    "        prepared_data.append(record)\n",
    "        \n",
    "        # 每1000行显示一次进度\n",
    "        if (index + 1) % 1000 == 0:\n",
    "            print(f\"准备进度: {index + 1}/{len(df)}\")\n",
    "    \n",
    "    return prepared_data\n",
    "\n",
    "# 准备数据\n",
    "print(\"开始准备数据...\")\n",
    "prepared_records = prepare_data_for_maxcompute(df_clean)\n",
    "print(f\"✅ 准备完成，共 {len(prepared_records)} 条记录\")\n",
    "\n",
    "print(\"前3条准备好的记录:\")\n",
    "for i, record in enumerate(prepared_records[:3]):\n",
    "    print(f\"  记录 {i+1}: {record}\")\n",
    "\n",
    "# 上传数据\n",
    "def upload_prepared_data(odps, records):\n",
    "    \"\"\"上传准备好的数据\"\"\"\n",
    "    print(\"\\n⬆️ 开始上传准备好的数据...\")\n",
    "    \n",
    "    try:\n",
    "        # 清空表\n",
    "        print(\"清空现有数据...\")\n",
    "        truncate_sql = \"TRUNCATE TABLE walmart_sales_raw\"\n",
    "        truncate_instance = odps.execute_sql(truncate_sql)\n",
    "        truncate_instance.wait_for_success()\n",
    "        print(\"✅ 表已清空\")\n",
    "        \n",
    "        # 获取表对象\n",
    "        table = odps.get_table('walmart_sales_raw')\n",
    "        \n",
    "        # 批量上传\n",
    "        batch_size = 1000\n",
    "        total_records = len(records)\n",
    "        \n",
    "        print(f\"开始批量上传，总计 {total_records} 条记录\")\n",
    "        \n",
    "        with table.open_writer() as writer:\n",
    "            for i in range(0, total_records, batch_size):\n",
    "                batch = records[i:i+batch_size]\n",
    "                \n",
    "                # 写入批次数据\n",
    "                for record in batch:\n",
    "                    writer.write(record)\n",
    "                \n",
    "                progress = ((i + len(batch)) / total_records) * 100\n",
    "                print(f\"批次 {i//batch_size + 1}: {len(batch)} 条记录 | 进度: {progress:.1f}%\")\n",
    "        \n",
    "        print(\"✅ 数据写入完成!\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ 上传失败: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return False\n",
    "\n",
    "# 执行上传\n",
    "success = upload_prepared_data(odps, prepared_records)\n",
    "\n",
    "# 验证结果\n",
    "if success:\n",
    "    print(\"\\n🔍 验证上传结果...\")\n",
    "    \n",
    "    def safe_execute_sql(odps, sql):\n",
    "        \"\"\"安全执行SQL\"\"\"\n",
    "        try:\n",
    "            instance = odps.execute_sql(sql)\n",
    "            instance.wait_for_success()\n",
    "            with instance.open_reader() as reader:\n",
    "                return list(reader)\n",
    "        except Exception as e:\n",
    "            print(f\"SQL执行失败: {e}\")\n",
    "            return None\n",
    "    \n",
    "    # 检查记录数\n",
    "    count_results = safe_execute_sql(odps, \"SELECT COUNT(*) as cnt FROM walmart_sales_raw\")\n",
    "    if count_results:\n",
    "        final_count = count_results[0][0]\n",
    "        print(f\"✅ 最终记录数: {final_count}\")\n",
    "    \n",
    "    # 查看样本数据\n",
    "    sample_results = safe_execute_sql(odps, \"SELECT * FROM walmart_sales_raw LIMIT 5\")\n",
    "    if sample_results:\n",
    "        print(\"\\n📋 MaxCompute中的样本数据:\")\n",
    "        for i, row in enumerate(sample_results):\n",
    "            print(f\"  行 {i+1}: 门店={row[0]}, 日期={row[1]}, 销量={row[2]}\")\n",
    "    \n",
    "    print(\"\\n🎉 数据上传完全成功!\")\n",
    "    print(\"现在可以在DataWorks中查询数据了!\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\n❌ 数据上传失败，请检查错误信息\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c0b0d0-c47d-4911-a15d-1e89b891721b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
